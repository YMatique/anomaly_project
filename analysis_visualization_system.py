#!/usr/bin/env python3
"""
Sistema de An√°lise e Visualiza√ß√£o para Detec√ß√£o de Anomalias - VERS√ÉO COMPLETA
Gera gr√°ficos de treinamento, m√©tricas e an√°lise de resultados
"""

import os
import sys
import json
import pickle
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Tuple, Optional, Union
import time
from datetime import datetime, timedelta
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_curve, auc, confusion_matrix, classification_report
)
from sklearn.model_selection import KFold
import warnings
warnings.filterwarnings('ignore')

# Configurar matplotlib para portugu√™s e estilo
plt.style.use('default')
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 12
plt.rcParams['axes.titlesize'] = 14
plt.rcParams['axes.labelsize'] = 12
plt.rcParams['xtick.labelsize'] = 10
plt.rcParams['ytick.labelsize'] = 10
plt.rcParams['legend.fontsize'] = 10

class TrainingVisualizer:
    """
    Classe para visualizar resultados de treinamento dos modelos
    Gera gr√°ficos de converg√™ncia, loss e m√©tricas
    """
    
    def __init__(self, output_dir: str = "data/analysis"):
        """
        Inicializa o visualizador
        
        Args:
            output_dir: Diret√≥rio para salvar gr√°ficos
        """
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        
        # Configurar cores
        self.colors = {
            'train': '#2E86AB',     # Azul
            'validation': '#A23B72', # Roxo
            'test': '#F18F01',      # Laranja
            'anomaly': '#C73E1D',   # Vermelho
            'normal': '#4CAF50',    # Verde
            'grid': '#E8E8E8'       # Cinza claro
        }
        
        print(f"TrainingVisualizer inicializado - output: {output_dir}")
    
    def plot_training_history(self, history: Dict, model_name: str = "Modelo") -> str:
        """
        Plota hist√≥rico de treinamento (loss e m√©tricas)
        
        Args:
            history: Hist√≥rico do treinamento (formato Keras)
            model_name: Nome do modelo para t√≠tulo
            
        Returns:
            Caminho do arquivo salvo
        """
        # Criar figura com subplots
        fig, axes = plt.subplots(1, 2, figsize=(15, 6))
        fig.suptitle(f'Hist√≥rico de Treinamento - {model_name}', fontsize=16, fontweight='bold')
        
        # Gr√°fico 1: Loss
        epochs = range(1, len(history['loss']) + 1)
        axes[0].plot(epochs, history['loss'], color=self.colors['train'], linewidth=2, label='Loss de Treinamento')
        if 'val_loss' in history:
            axes[0].plot(epochs, history['val_loss'], color=self.colors['validation'], linewidth=2, label='Loss de Valida√ß√£o')
        
        axes[0].set_title('Evolu√ß√£o do Loss (MSE)', fontweight='bold')
        axes[0].set_xlabel('√âpocas')
        axes[0].set_ylabel('MSE')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)
        axes[0].set_yscale('log')  # Escala logar√≠tmica para loss
        
        # Gr√°fico 2: MAE (Mean Absolute Error)
        if 'mae' in history:
            axes[1].plot(epochs, history['mae'], color=self.colors['train'], linewidth=2, label='MAE de Treinamento')
        if 'val_mae' in history:
            axes[1].plot(epochs, history['val_mae'], color=self.colors['validation'], linewidth=2, label='MAE de Valida√ß√£o')
        
        axes[1].set_title('Mean Absolute Error (MAE)', fontweight='bold')
        axes[1].set_xlabel('√âpocas')
        axes[1].set_ylabel('MAE')
        axes[1].legend()
        axes[1].grid(True, alpha=0.3)
        
        # Salvar
        filename = f"training_history_{model_name.lower().replace(' ', '_')}.png"
        filepath = os.path.join(self.output_dir, filename)
        plt.tight_layout()
        plt.savefig(filepath, dpi=300, bbox_inches='tight', facecolor='white')
        plt.close()
        
        print(f"Gr√°fico de treinamento salvo: {filepath}")
        return filepath


class MetricsAnalyzer:
    """
    Classe para an√°lise de m√©tricas de performance
    Calcula e visualiza acur√°cia, precis√£o, recall, F1-score, etc.
    """
    
    def __init__(self, output_dir: str = "data/analysis"):
        """
        Inicializa o analisador de m√©tricas
        
        Args:
            output_dir: Diret√≥rio para salvar gr√°ficos
        """
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        
        print(f"MetricsAnalyzer inicializado - output: {output_dir}")
    
    def calculate_metrics(self, y_true: np.ndarray, y_pred: np.ndarray, 
                         y_scores: np.ndarray = None) -> Dict:
        """
        Calcula m√©tricas completas de classifica√ß√£o
        
        Args:
            y_true: Labels verdadeiros (0/1)
            y_pred: Predi√ß√µes (0/1)
            y_scores: Scores de confian√ßa (opcional)
            
        Returns:
            Dict com todas as m√©tricas
        """
        # M√©tricas b√°sicas
        accuracy = accuracy_score(y_true, y_pred)
        precision = precision_score(y_true, y_pred, zero_division=0)
        recall = recall_score(y_true, y_pred, zero_division=0)
        f1 = f1_score(y_true, y_pred, zero_division=0)
        
        # Matriz de confus√£o
        cm = confusion_matrix(y_true, y_pred)
        tn, fp, fn, tp = cm.ravel() if cm.size == 4 else (0, 0, 0, 0)
        
        # M√©tricas derivadas
        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0  # Taxa de Falsos Positivos
        fnr = fn / (fn + tp) if (fn + tp) > 0 else 0  # Taxa de Falsos Negativos
        
        metrics = {
            'accuracy': float(accuracy),
            'precision': float(precision),
            'recall': float(recall),
            'f1_score': float(f1),
            'specificity': float(specificity),
            'false_positive_rate': float(fpr),
            'false_negative_rate': float(fnr),
            'true_positives': int(tp),
            'true_negatives': int(tn),
            'false_positives': int(fp),
            'false_negatives': int(fn),
            'total_samples': len(y_true)
        }
        
        # ROC AUC se scores dispon√≠veis
        if y_scores is not None:
            try:
                fpr_curve, tpr_curve, _ = roc_curve(y_true, y_scores)
                roc_auc = auc(fpr_curve, tpr_curve)
                metrics['roc_auc'] = float(roc_auc)
                metrics['roc_curve'] = {
                    'fpr': fpr_curve.tolist(),
                    'tpr': tpr_curve.tolist()
                }
            except Exception as e:
                print(f"Erro ao calcular ROC AUC: {e}")
        
        # Adicionar timestamp
        metrics['timestamp'] = datetime.now().isoformat()
        
        print(f"M√©tricas calculadas - Acur√°cia: {accuracy:.3f}, F1: {f1:.3f}")
        return metrics
    
    def plot_confusion_matrix(self, y_true: np.ndarray, y_pred: np.ndarray, 
                             title: str = "Matriz de Confus√£o") -> str:
        """
        Plota matriz de confus√£o
        
        Args:
            y_true: Labels verdadeiros
            y_pred: Predi√ß√µes
            title: T√≠tulo do gr√°fico
            
        Returns:
            Caminho do arquivo salvo
        """
        # Calcular matriz de confus√£o
        cm = confusion_matrix(y_true, y_pred)
        
        # Criar figura
        plt.figure(figsize=(10, 8))
        
        # Plot com seaborn
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                   xticklabels=['Normal', 'Anomalia'],
                   yticklabels=['Normal', 'Anomalia'],
                   cbar_kws={'label': 'N√∫mero de Amostras'})
        
        plt.title(title, fontsize=16, fontweight='bold', pad=20)
        plt.xlabel('Predi√ß√µes', fontsize=14)
        plt.ylabel('Valores Reais', fontsize=14)
        
        # Adicionar estat√≠sticas
        tn, fp, fn, tp = cm.ravel() if cm.size == 4 else (0, 0, 0, 0)
        accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0
        
        plt.figtext(0.02, 0.02, f'Acur√°cia: {accuracy:.3f}', fontsize=12,
                   bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue"))
        
        # Salvar
        filename = f"confusion_matrix_{int(time.time())}.png"
        filepath = os.path.join(self.output_dir, filename)
        plt.tight_layout()
        plt.savefig(filepath, dpi=300, bbox_inches='tight', facecolor='white')
        plt.close()
        
        print(f"Matriz de confus√£o salva: {filepath}")
        return filepath
    
    def plot_roc_curve(self, y_true: np.ndarray, y_scores: np.ndarray,
                       title: str = "Curva ROC") -> str:
        """
        Plota curva ROC
        
        Args:
            y_true: Labels verdadeiros
            y_scores: Scores de confian√ßa
            title: T√≠tulo do gr√°fico
            
        Returns:
            Caminho do arquivo salvo
        """
        # Calcular ROC
        fpr, tpr, thresholds = roc_curve(y_true, y_scores)
        roc_auc = auc(fpr, tpr)
        
        # Criar figura
        plt.figure(figsize=(10, 8))
        
        # Plot da curva ROC
        plt.plot(fpr, tpr, color='#2E86AB', linewidth=3, 
                label=f'Curva ROC (AUC = {roc_auc:.3f})')
        
        # Linha diagonal (classificador aleat√≥rio)
        plt.plot([0, 1], [0, 1], color='#C73E1D', linestyle='--', linewidth=2,
                label='Classificador Aleat√≥rio (AUC = 0.5)')
        
        # Configura√ß√µes
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('Taxa de Falsos Positivos (1 - Especificidade)', fontsize=14)
        plt.ylabel('Taxa de Verdadeiros Positivos (Sensibilidade)', fontsize=14)
        plt.title(title, fontsize=16, fontweight='bold')
        plt.legend(loc="lower right", fontsize=12)
        plt.grid(True, alpha=0.3)
        
        # Salvar
        filename = f"roc_curve_{int(time.time())}.png"
        filepath = os.path.join(self.output_dir, filename)
        plt.tight_layout()
        plt.savefig(filepath, dpi=300, bbox_inches='tight', facecolor='white')
        plt.close()
        
        print(f"Curva ROC salva: {filepath}")
        return filepath


class ComprehensiveAnalyzer:
    """
    Classe principal que integra todos os analisadores
    Gera relat√≥rios completos do sistema
    """
    
    def __init__(self, config_file: str = "config.json"):
        """
        Inicializa o analisador completo
        
        Args:
            config_file: Arquivo de configura√ß√£o
        """
        self.output_dir = "data/analysis"
        os.makedirs(self.output_dir, exist_ok=True)
        
        # Inicializar sub-analisadores
        self.training_visualizer = TrainingVisualizer(self.output_dir)
        self.metrics_analyzer = MetricsAnalyzer(self.output_dir)
        
        print("ComprehensiveAnalyzer inicializado")
    
    def generate_training_report(self, training_histories: Dict[str, Dict],
                                model_paths: Dict[str, str] = None) -> Dict[str, str]:
        """
        Gera relat√≥rio completo de treinamento
        
        Args:
            training_histories: Hist√≥ricos de treinamento dos modelos
            model_paths: Caminhos dos modelos salvos
            
        Returns:
            Dict com caminhos dos arquivos gerados
        """
        print("Gerando relat√≥rio completo de treinamento...")
        
        generated_files = {}
        
        # 1. Gr√°ficos individuais de treinamento
        for model_name, history in training_histories.items():
            filepath = self.training_visualizer.plot_training_history(history, model_name)
            generated_files[f"training_{model_name.lower()}"] = filepath
        
        # 2. Relat√≥rio de texto
        report_text = self._generate_training_text_report(training_histories, model_paths)
        report_file = os.path.join(self.output_dir, "training_report.md")
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_text)
        
        generated_files["training_report"] = report_file
        
        print(f"Relat√≥rio de treinamento gerado - {len(generated_files)} arquivos")
        return generated_files
    
    def generate_evaluation_report(self, y_true: np.ndarray, y_pred: np.ndarray,
                                  y_scores: np.ndarray = None,
                                  model_name: str = "Sistema") -> Dict[str, str]:
        """
        Gera relat√≥rio completo de avalia√ß√£o
        
        Args:
            y_true: Labels verdadeiros
            y_pred: Predi√ß√µes
            y_scores: Scores de confian√ßa (opcional)
            model_name: Nome do modelo
            
        Returns:
            Dict com caminhos dos arquivos gerados
        """
        print(f"Gerando relat√≥rio de avalia√ß√£o para {model_name}")
        
        generated_files = {}
        
        # 1. Calcular m√©tricas
        metrics = self.metrics_analyzer.calculate_metrics(y_true, y_pred, y_scores)
        
        # 2. Matriz de confus√£o
        cm_path = self.metrics_analyzer.plot_confusion_matrix(
            y_true, y_pred, f"Matriz de Confus√£o - {model_name}")
        generated_files["confusion_matrix"] = cm_path
        
        # 3. Curva ROC (se scores dispon√≠veis)
        if y_scores is not None:
            roc_path = self.metrics_analyzer.plot_roc_curve(
                y_true, y_scores, f"Curva ROC - {model_name}")
            generated_files["roc_curve"] = roc_path
        
        # 4. Relat√≥rio de classifica√ß√£o
        report_text = f"""
=== RELAT√ìRIO DE CLASSIFICA√á√ÉO ===
Data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Modelo: {model_name}

=== M√âTRICAS PRINCIPAIS ===
Acur√°cia:               {metrics['accuracy']:.3f}
Precis√£o:               {metrics['precision']:.3f}
Recall (Sensibilidade): {metrics['recall']:.3f}
F1-Score:               {metrics['f1_score']:.3f}
Especificidade:         {metrics['specificity']:.3f}

=== TAXAS DE ERRO ===
Taxa de Falsos Positivos: {metrics['false_positive_rate']:.3f}
Taxa de Falsos Negativos: {metrics['false_negative_rate']:.3f}

=== MATRIZ DE CONFUS√ÉO ===
                Predito
Real        Normal  Anomalia
Normal      {metrics['true_negatives']:6d}  {metrics['false_positives']:8d}
Anomalia    {metrics['false_negatives']:6d}  {metrics['true_positives']:8d}

=== ESTAT√çSTICAS DETALHADAS ===
Total de Amostras:        {metrics['total_samples']}
Verdadeiros Positivos:    {metrics['true_positives']}
Verdadeiros Negativos:    {metrics['true_negatives']}
Falsos Positivos:         {metrics['false_positives']}
Falsos Negativos:         {metrics['false_negatives']}
        """
        
        report_path = os.path.join(self.output_dir, f"classification_report_{model_name.lower().replace(' ', '_')}.txt")
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_text)
        generated_files["classification_report"] = report_path
        
        # 5. Salvar m√©tricas em JSON
        metrics_file = os.path.join(self.output_dir, f"metrics_{model_name.lower().replace(' ', '_')}.json")
        with open(metrics_file, 'w') as f:
            json.dump(metrics, f, indent=2, default=str)
        generated_files["metrics_json"] = metrics_file
        
        print(f"Relat√≥rio de avalia√ß√£o gerado - {len(generated_files)} arquivos")
        return generated_files
    
    def generate_complete_analysis(self, data_package: Dict) -> Dict[str, str]:
        """
        Gera an√°lise completa do sistema
        
        Args:
            data_package: Pacote com todos os dados necess√°rios
                - training_histories: Hist√≥ricos de treinamento
                - evaluation_data: Dados de avalia√ß√£o (y_true, y_pred, y_scores)
                - performance_data: Dados de performance
                - model_info: Informa√ß√µes dos modelos
                
        Returns:
            Dict com todos os arquivos gerados
        """
        print("üöÄ Iniciando an√°lise completa do sistema...")
        
        all_generated_files = {}
        
        # 1. Relat√≥rio de Treinamento
        if 'training_histories' in data_package:
            training_files = self.generate_training_report(
                data_package['training_histories'],
                data_package.get('model_paths', {})
            )
            all_generated_files.update(training_files)
        
        # 2. Relat√≥rio de Avalia√ß√£o
        if 'evaluation_data' in data_package:
            eval_data = data_package['evaluation_data']
            eval_files = self.generate_evaluation_report(
                eval_data['y_true'],
                eval_data['y_pred'],
                eval_data.get('y_scores'),
                eval_data.get('model_name', 'Sistema')
            )
            all_generated_files.update(eval_files)
        
        # 3. Relat√≥rio Final em HTML
        html_report = self._generate_html_report(all_generated_files, data_package)
        html_file = os.path.join(self.output_dir, "complete_analysis_report.html")
        
        with open(html_file, 'w', encoding='utf-8') as f:
            f.write(html_report)
        
        all_generated_files["html_report"] = html_file
        
        # 4. README com instru√ß√µes
        readme_content = self._generate_readme(all_generated_files)
        readme_file = os.path.join(self.output_dir, "README.md")
        
        with open(readme_file, 'w', encoding='utf-8') as f:
            f.write(readme_content)
        
        all_generated_files["readme"] = readme_file
        
        print(f"‚úÖ An√°lise completa finalizada - {len(all_generated_files)} arquivos gerados")
        return all_generated_files
    
    def _generate_training_text_report(self, histories: Dict[str, Dict],
                                     model_paths: Dict[str, str] = None) -> str:
        """Gera relat√≥rio de texto para treinamento"""
        
        report = f"""# Relat√≥rio de Treinamento - Sistema de Detec√ß√£o de Anomalias

**Data:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## Resumo Executivo

Este relat√≥rio apresenta os resultados do treinamento dos modelos de deep learning implementados no sistema de detec√ß√£o de anomalias.

## Modelos Treinados

"""
        
        for model_name, history in histories.items():
            epochs = len(history['loss'])
            final_loss = history['loss'][-1]
            min_loss = min(history['loss'])
            
            report += f"""### {model_name}

- **√âpocas treinadas:** {epochs}
- **Loss final:** {final_loss:.6f}
- **Melhor loss:** {min_loss:.6f}
- **Converg√™ncia:** {'Sim' if final_loss < min_loss * 1.1 else 'Necessita mais √©pocas'}

"""
            
            if 'val_loss' in history:
                val_loss = history['val_loss'][-1]
                min_val_loss = min(history['val_loss'])
                overfitting = val_loss > min_val_loss * 1.2
                
                report += f"""- **Loss de valida√ß√£o final:** {val_loss:.6f}
- **Melhor loss de valida√ß√£o:** {min_val_loss:.6f}
- **Overfitting detectado:** {'Sim' if overfitting else 'N√£o'}

"""
        
        report += """## An√°lise de Converg√™ncia

Os gr√°ficos de converg√™ncia mostram a evolu√ß√£o do loss durante o treinamento. Uma boa converg√™ncia √© caracterizada por:

1. **Diminui√ß√£o consistente do loss**
2. **Estabiliza√ß√£o em valor baixo**
3. **Proximidade entre loss de treino e valida√ß√£o**

## Recomenda√ß√µes

- Monitore overfitting atrav√©s da diverg√™ncia entre loss de treino e valida√ß√£o
- Considere early stopping se o loss de valida√ß√£o parar de melhorar
- Ajuste learning rate se a converg√™ncia for muito lenta ou inst√°vel

"""
        
        return report
    
    def _generate_html_report(self, files: Dict[str, str], data_package: Dict) -> str:
        """Gera relat√≥rio HTML completo"""
        
        html = f"""<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Relat√≥rio de An√°lise - Sistema de Detec√ß√£o de Anomalias</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 40px; background-color: #f5f5f5; }}
        .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 30px; border-radius: 10px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); }}
        h1 {{ color: #2E86AB; text-align: center; border-bottom: 3px solid #2E86AB; padding-bottom: 10px; }}
        h2 {{ color: #333; border-left: 4px solid #2E86AB; padding-left: 15px; }}
        h3 {{ color: #666; }}
        .metric {{ background: #f8f9fa; padding: 15px; margin: 10px 0; border-radius: 5px; border-left: 4px solid #4CAF50; }}
        .image-container {{ text-align: center; margin: 20px 0; }}
        .image-container img {{ max-width: 100%; height: auto; border: 1px solid #ddd; border-radius: 5px; }}
        table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}
        th, td {{ padding: 12px; text-align: left; border-bottom: 1px solid #ddd; }}
        th {{ background-color: #2E86AB; color: white; }}
        .success {{ color: #4CAF50; font-weight: bold; }}
        .footer {{ text-align: center; margin-top: 40px; padding-top: 20px; border-top: 1px solid #ddd; color: #666; }}
    </style>
</head>
<body>
    <div class="container">
        <h1>üö® Sistema de Detec√ß√£o de Anomalias</h1>
        <h2>Relat√≥rio de An√°lise Completa</h2>
        
        <div class="metric">
            <strong>Data de Gera√ß√£o:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}<br>
            <strong>Arquivos Gerados:</strong> {len(files)}<br>
            <strong>Status:</strong> <span class="success">‚úÖ Completo</span>
        </div>
        
        <h2>üìà An√°lise de Treinamento</h2>
        <p>Esta se√ß√£o apresenta os resultados do treinamento dos modelos de deep learning.</p>
        
        <h2>üìä An√°lise de Performance</h2>
        <p>M√©tricas de classifica√ß√£o e an√°lise de performance do sistema.</p>
        
        <h2>üìÅ Arquivos Gerados</h2>
        <table>
            <tr><th>Tipo</th><th>Arquivo</th><th>Descri√ß√£o</th></tr>
"""
        
        file_descriptions = {
            "training_cae": "Gr√°fico de treinamento do CAE",
            "training_convlstm": "Gr√°fico de treinamento do ConvLSTM",
            "confusion_matrix": "Matriz de confus√£o",
            "roc_curve": "Curva ROC",
            "classification_report": "Relat√≥rio detalhado de classifica√ß√£o",
            "training_report": "Relat√≥rio completo de treinamento"
        }
        
        for file_type, filepath in files.items():
            filename = os.path.basename(filepath)
            description = file_descriptions.get(file_type, "Arquivo de an√°lise")
            html += f"<tr><td>{file_type.replace('_', ' ').title()}</td><td>{filename}</td><td>{description}</td></tr>"
        
        html += """
        </table>
        
        <div class="footer">
            <p>Relat√≥rio gerado automaticamente pelo Sistema de Detec√ß√£o de Anomalias</p>
            <p>üî¨ Desenvolvido com Python, TensorFlow e OpenCV</p>
        </div>
    </div>
</body>
</html>
"""
        
        return html
    
    def _generate_readme(self, files: Dict[str, str]) -> str:
        """Gera README com instru√ß√µes"""
        
        readme = f"""# üìä Relat√≥rio de An√°lise - Sistema de Detec√ß√£o de Anomalias

**Data de Gera√ß√£o:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## üìÅ Arquivos Gerados

Este diret√≥rio cont√©m {len(files)} arquivos de an√°lise gerados automaticamente:

### üìà Gr√°ficos de Treinamento
"""
        
        for file_type, filepath in files.items():
            if "training" in file_type:
                filename = os.path.basename(filepath)
                readme += f"- `{filename}` - Hist√≥rico de treinamento\n"
        
        readme += """
### üìä M√©tricas de Avalia√ß√£o
"""
        
        for file_type, filepath in files.items():
            if file_type in ["confusion_matrix", "roc_curve", "classification_report"]:
                filename = os.path.basename(filepath)
                readme += f"- `{filename}` - An√°lise de performance\n"
        
        readme += f"""
## üöÄ Como Usar

1. **Visualizar Relat√≥rio HTML:** Abra `complete_analysis_report.html` no navegador
2. **Gr√°ficos:** Todas as imagens est√£o em alta resolu√ß√£o (300 DPI)
3. **Dados Brutos:** Arquivos JSON cont√™m m√©tricas num√©ricas
4. **Relat√≥rios de Texto:** Arquivos .txt e .md para documenta√ß√£o

---
*Relat√≥rio gerado automaticamente pelo Sistema de Detec√ß√£o de Anomalias*
"""
        
        return readme


# Exemplo de uso b√°sico
if __name__ == "__main__":
    print("Sistema de An√°lise e Visualiza√ß√£o - Teste")
    
    # Criar analisador
    analyzer = ComprehensiveAnalyzer()
    
    print("‚úÖ Sistema carregado com sucesso!")
    print("Use: from analysis_visualization_system import ComprehensiveAnalyzer")